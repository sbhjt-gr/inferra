/**
 * This code was generated by [react-native-codegen](https://www.npmjs.com/package/react-native-codegen).
 *
 * Do not edit this file as changes may cause incorrect behavior and will be lost
 * once the code is regenerated.
 *
 * @generated by codegen project: GenerateModuleObjCpp
 *
 * We create an umbrella header (and corresponding implementation) here since
 * Cxx compilation in BUCK has a limitation: source-code producing genrule()s
 * must have a single output. More files => more genrule()s => slower builds.
 */

#ifndef __cplusplus
#error This file must be compiled as Obj-C++. If you are importing it, you must change your file extension to .mm.
#endif

// Avoid multiple includes of RNLlamaSpec symbols
#ifndef RNLlamaSpec_H
#define RNLlamaSpec_H

#import <Foundation/Foundation.h>
#import <RCTRequired/RCTRequired.h>
#import <RCTTypeSafety/RCTConvertHelpers.h>
#import <RCTTypeSafety/RCTTypedModuleConstants.h>
#import <React/RCTBridgeModule.h>
#import <React/RCTCxxConvert.h>
#import <React/RCTManagedPointer.h>
#import <ReactCommon/RCTTurboModule.h>
#import <optional>
#import <vector>

namespace JS {
  namespace NativeRNLlama {
    struct NativeContextParamsLora_listElement {
      NSString *path() const;
      std::optional<double> scaled() const;

      NativeContextParamsLora_listElement(NSDictionary *const v) : _v(v) {}
    private:
      NSDictionary *_v;
    };
  }
}

@interface RCTCxxConvert (NativeRNLlama_NativeContextParamsLora_listElement)
+ (RCTManagedPointer *)JS_NativeRNLlama_NativeContextParamsLora_listElement:(id)json;
@end
namespace JS {
  namespace NativeRNLlama {
    struct NativeContextParams {
      NSString *model() const;
      NSString *chat_template() const;
      NSString *reasoning_format() const;
      std::optional<bool> is_model_asset() const;
      std::optional<bool> use_progress_callback() const;
      std::optional<double> n_ctx() const;
      std::optional<double> n_batch() const;
      std::optional<double> n_ubatch() const;
      std::optional<double> n_threads() const;
      std::optional<double> n_gpu_layers() const;
      std::optional<bool> no_gpu_devices() const;
      std::optional<bool> flash_attn() const;
      NSString *cache_type_k() const;
      NSString *cache_type_v() const;
      std::optional<bool> use_mlock() const;
      std::optional<bool> use_mmap() const;
      std::optional<bool> vocab_only() const;
      NSString *lora() const;
      std::optional<double> lora_scaled() const;
      std::optional<facebook::react::LazyVector<JS::NativeRNLlama::NativeContextParamsLora_listElement>> lora_list() const;
      std::optional<double> rope_freq_base() const;
      std::optional<double> rope_freq_scale() const;
      std::optional<double> pooling_type() const;
      std::optional<bool> embedding() const;
      std::optional<double> embd_normalize() const;

      NativeContextParams(NSDictionary *const v) : _v(v) {}
    private:
      NSDictionary *_v;
    };
  }
}

@interface RCTCxxConvert (NativeRNLlama_NativeContextParams)
+ (RCTManagedPointer *)JS_NativeRNLlama_NativeContextParams:(id)json;
@end
namespace JS {
  namespace NativeRNLlama {
    struct SpecGetFormattedChatParams {
      std::optional<bool> jinja() const;
      NSString *json_schema() const;
      NSString *tools() const;
      NSString *parallel_tool_calls() const;
      NSString *tool_choice() const;

      SpecGetFormattedChatParams(NSDictionary *const v) : _v(v) {}
    private:
      NSDictionary *_v;
    };
  }
}

@interface RCTCxxConvert (NativeRNLlama_SpecGetFormattedChatParams)
+ (RCTManagedPointer *)JS_NativeRNLlama_SpecGetFormattedChatParams:(id)json;
@end
namespace JS {
  namespace NativeRNLlama {
    struct NativeCompletionParamsGrammar_triggersElement {
      double type() const;
      NSString *value() const;
      double token() const;

      NativeCompletionParamsGrammar_triggersElement(NSDictionary *const v) : _v(v) {}
    private:
      NSDictionary *_v;
    };
  }
}

@interface RCTCxxConvert (NativeRNLlama_NativeCompletionParamsGrammar_triggersElement)
+ (RCTManagedPointer *)JS_NativeRNLlama_NativeCompletionParamsGrammar_triggersElement:(id)json;
@end
namespace JS {
  namespace NativeRNLlama {
    struct NativeCompletionParams {
      NSString *prompt() const;
      std::optional<double> n_threads() const;
      NSString *json_schema() const;
      NSString *grammar() const;
      std::optional<bool> grammar_lazy() const;
      std::optional<facebook::react::LazyVector<JS::NativeRNLlama::NativeCompletionParamsGrammar_triggersElement>> grammar_triggers() const;
      std::optional<facebook::react::LazyVector<NSString *>> preserved_tokens() const;
      std::optional<double> chat_format() const;
      std::optional<facebook::react::LazyVector<NSString *>> stop() const;
      std::optional<double> n_predict() const;
      std::optional<double> n_probs() const;
      std::optional<double> top_k() const;
      std::optional<double> top_p() const;
      std::optional<double> min_p() const;
      std::optional<double> xtc_probability() const;
      std::optional<double> xtc_threshold() const;
      std::optional<double> typical_p() const;
      std::optional<double> temperature() const;
      std::optional<double> penalty_last_n() const;
      std::optional<double> penalty_repeat() const;
      std::optional<double> penalty_freq() const;
      std::optional<double> penalty_present() const;
      std::optional<double> mirostat() const;
      std::optional<double> mirostat_tau() const;
      std::optional<double> mirostat_eta() const;
      std::optional<double> dry_multiplier() const;
      std::optional<double> dry_base() const;
      std::optional<double> dry_allowed_length() const;
      std::optional<double> dry_penalty_last_n() const;
      std::optional<facebook::react::LazyVector<NSString *>> dry_sequence_breakers() const;
      std::optional<double> top_n_sigma() const;
      std::optional<bool> ignore_eos() const;
      std::optional<facebook::react::LazyVector<facebook::react::LazyVector<double>>> logit_bias() const;
      std::optional<double> seed() const;
      bool emit_partial_completion() const;

      NativeCompletionParams(NSDictionary *const v) : _v(v) {}
    private:
      NSDictionary *_v;
    };
  }
}

@interface RCTCxxConvert (NativeRNLlama_NativeCompletionParams)
+ (RCTManagedPointer *)JS_NativeRNLlama_NativeCompletionParams:(id)json;
@end
namespace JS {
  namespace NativeRNLlama {
    struct NativeEmbeddingParams {
      std::optional<double> embd_normalize() const;

      NativeEmbeddingParams(NSDictionary *const v) : _v(v) {}
    private:
      NSDictionary *_v;
    };
  }
}

@interface RCTCxxConvert (NativeRNLlama_NativeEmbeddingParams)
+ (RCTManagedPointer *)JS_NativeRNLlama_NativeEmbeddingParams:(id)json;
@end
@protocol NativeRNLlamaSpec <RCTBridgeModule, RCTTurboModule>

- (void)toggleNativeLog:(BOOL)enabled
                resolve:(RCTPromiseResolveBlock)resolve
                 reject:(RCTPromiseRejectBlock)reject;
- (void)setContextLimit:(double)limit
                resolve:(RCTPromiseResolveBlock)resolve
                 reject:(RCTPromiseRejectBlock)reject;
- (void)modelInfo:(NSString *)path
             skip:(NSArray *)skip
          resolve:(RCTPromiseResolveBlock)resolve
           reject:(RCTPromiseRejectBlock)reject;
- (void)initContext:(double)contextId
             params:(JS::NativeRNLlama::NativeContextParams &)params
            resolve:(RCTPromiseResolveBlock)resolve
             reject:(RCTPromiseRejectBlock)reject;
- (void)getFormattedChat:(double)contextId
                messages:(NSString *)messages
            chatTemplate:(NSString *)chatTemplate
                  params:(JS::NativeRNLlama::SpecGetFormattedChatParams &)params
                 resolve:(RCTPromiseResolveBlock)resolve
                  reject:(RCTPromiseRejectBlock)reject;
- (void)loadSession:(double)contextId
           filepath:(NSString *)filepath
            resolve:(RCTPromiseResolveBlock)resolve
             reject:(RCTPromiseRejectBlock)reject;
- (void)saveSession:(double)contextId
           filepath:(NSString *)filepath
               size:(double)size
            resolve:(RCTPromiseResolveBlock)resolve
             reject:(RCTPromiseRejectBlock)reject;
- (void)completion:(double)contextId
            params:(JS::NativeRNLlama::NativeCompletionParams &)params
           resolve:(RCTPromiseResolveBlock)resolve
            reject:(RCTPromiseRejectBlock)reject;
- (void)stopCompletion:(double)contextId
               resolve:(RCTPromiseResolveBlock)resolve
                reject:(RCTPromiseRejectBlock)reject;
- (void)tokenize:(double)contextId
            text:(NSString *)text
         resolve:(RCTPromiseResolveBlock)resolve
          reject:(RCTPromiseRejectBlock)reject;
- (void)detokenize:(double)contextId
            tokens:(NSArray *)tokens
           resolve:(RCTPromiseResolveBlock)resolve
            reject:(RCTPromiseRejectBlock)reject;
- (void)embedding:(double)contextId
             text:(NSString *)text
           params:(JS::NativeRNLlama::NativeEmbeddingParams &)params
          resolve:(RCTPromiseResolveBlock)resolve
           reject:(RCTPromiseRejectBlock)reject;
- (void)bench:(double)contextId
           pp:(double)pp
           tg:(double)tg
           pl:(double)pl
           nr:(double)nr
      resolve:(RCTPromiseResolveBlock)resolve
       reject:(RCTPromiseRejectBlock)reject;
- (void)applyLoraAdapters:(double)contextId
             loraAdapters:(NSArray *)loraAdapters
                  resolve:(RCTPromiseResolveBlock)resolve
                   reject:(RCTPromiseRejectBlock)reject;
- (void)removeLoraAdapters:(double)contextId
                   resolve:(RCTPromiseResolveBlock)resolve
                    reject:(RCTPromiseRejectBlock)reject;
- (void)getLoadedLoraAdapters:(double)contextId
                      resolve:(RCTPromiseResolveBlock)resolve
                       reject:(RCTPromiseRejectBlock)reject;
- (void)releaseContext:(double)contextId
               resolve:(RCTPromiseResolveBlock)resolve
                reject:(RCTPromiseRejectBlock)reject;
- (void)releaseAllContexts:(RCTPromiseResolveBlock)resolve
                    reject:(RCTPromiseRejectBlock)reject;

@end

@interface NativeRNLlamaSpecBase : NSObject {
@protected
facebook::react::EventEmitterCallback _eventEmitterCallback;
}
- (void)setEventEmitterCallback:(EventEmitterCallbackWrapper *)eventEmitterCallbackWrapper;


@end

namespace facebook::react {
  /**
   * ObjC++ class for module 'NativeRNLlama'
   */
  class JSI_EXPORT NativeRNLlamaSpecJSI : public ObjCTurboModule {
  public:
    NativeRNLlamaSpecJSI(const ObjCTurboModule::InitParams &params);
  };
} // namespace facebook::react
inline NSString *JS::NativeRNLlama::NativeContextParamsLora_listElement::path() const
{
  id const p = _v[@"path"];
  return RCTBridgingToString(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParamsLora_listElement::scaled() const
{
  id const p = _v[@"scaled"];
  return RCTBridgingToOptionalDouble(p);
}
inline NSString *JS::NativeRNLlama::NativeContextParams::model() const
{
  id const p = _v[@"model"];
  return RCTBridgingToString(p);
}
inline NSString *JS::NativeRNLlama::NativeContextParams::chat_template() const
{
  id const p = _v[@"chat_template"];
  return RCTBridgingToOptionalString(p);
}
inline NSString *JS::NativeRNLlama::NativeContextParams::reasoning_format() const
{
  id const p = _v[@"reasoning_format"];
  return RCTBridgingToOptionalString(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeContextParams::is_model_asset() const
{
  id const p = _v[@"is_model_asset"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeContextParams::use_progress_callback() const
{
  id const p = _v[@"use_progress_callback"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::n_ctx() const
{
  id const p = _v[@"n_ctx"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::n_batch() const
{
  id const p = _v[@"n_batch"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::n_ubatch() const
{
  id const p = _v[@"n_ubatch"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::n_threads() const
{
  id const p = _v[@"n_threads"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::n_gpu_layers() const
{
  id const p = _v[@"n_gpu_layers"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeContextParams::no_gpu_devices() const
{
  id const p = _v[@"no_gpu_devices"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeContextParams::flash_attn() const
{
  id const p = _v[@"flash_attn"];
  return RCTBridgingToOptionalBool(p);
}
inline NSString *JS::NativeRNLlama::NativeContextParams::cache_type_k() const
{
  id const p = _v[@"cache_type_k"];
  return RCTBridgingToOptionalString(p);
}
inline NSString *JS::NativeRNLlama::NativeContextParams::cache_type_v() const
{
  id const p = _v[@"cache_type_v"];
  return RCTBridgingToOptionalString(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeContextParams::use_mlock() const
{
  id const p = _v[@"use_mlock"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeContextParams::use_mmap() const
{
  id const p = _v[@"use_mmap"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeContextParams::vocab_only() const
{
  id const p = _v[@"vocab_only"];
  return RCTBridgingToOptionalBool(p);
}
inline NSString *JS::NativeRNLlama::NativeContextParams::lora() const
{
  id const p = _v[@"lora"];
  return RCTBridgingToOptionalString(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::lora_scaled() const
{
  id const p = _v[@"lora_scaled"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<facebook::react::LazyVector<JS::NativeRNLlama::NativeContextParamsLora_listElement>> JS::NativeRNLlama::NativeContextParams::lora_list() const
{
  id const p = _v[@"lora_list"];
  return RCTBridgingToOptionalVec(p, ^JS::NativeRNLlama::NativeContextParamsLora_listElement(id itemValue_0) { return JS::NativeRNLlama::NativeContextParamsLora_listElement(itemValue_0); });
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::rope_freq_base() const
{
  id const p = _v[@"rope_freq_base"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::rope_freq_scale() const
{
  id const p = _v[@"rope_freq_scale"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::pooling_type() const
{
  id const p = _v[@"pooling_type"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeContextParams::embedding() const
{
  id const p = _v[@"embedding"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::embd_normalize() const
{
  id const p = _v[@"embd_normalize"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<bool> JS::NativeRNLlama::SpecGetFormattedChatParams::jinja() const
{
  id const p = _v[@"jinja"];
  return RCTBridgingToOptionalBool(p);
}
inline NSString *JS::NativeRNLlama::SpecGetFormattedChatParams::json_schema() const
{
  id const p = _v[@"json_schema"];
  return RCTBridgingToOptionalString(p);
}
inline NSString *JS::NativeRNLlama::SpecGetFormattedChatParams::tools() const
{
  id const p = _v[@"tools"];
  return RCTBridgingToOptionalString(p);
}
inline NSString *JS::NativeRNLlama::SpecGetFormattedChatParams::parallel_tool_calls() const
{
  id const p = _v[@"parallel_tool_calls"];
  return RCTBridgingToOptionalString(p);
}
inline NSString *JS::NativeRNLlama::SpecGetFormattedChatParams::tool_choice() const
{
  id const p = _v[@"tool_choice"];
  return RCTBridgingToOptionalString(p);
}
inline double JS::NativeRNLlama::NativeCompletionParamsGrammar_triggersElement::type() const
{
  id const p = _v[@"type"];
  return RCTBridgingToDouble(p);
}
inline NSString *JS::NativeRNLlama::NativeCompletionParamsGrammar_triggersElement::value() const
{
  id const p = _v[@"value"];
  return RCTBridgingToString(p);
}
inline double JS::NativeRNLlama::NativeCompletionParamsGrammar_triggersElement::token() const
{
  id const p = _v[@"token"];
  return RCTBridgingToDouble(p);
}
inline NSString *JS::NativeRNLlama::NativeCompletionParams::prompt() const
{
  id const p = _v[@"prompt"];
  return RCTBridgingToString(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::n_threads() const
{
  id const p = _v[@"n_threads"];
  return RCTBridgingToOptionalDouble(p);
}
inline NSString *JS::NativeRNLlama::NativeCompletionParams::json_schema() const
{
  id const p = _v[@"json_schema"];
  return RCTBridgingToOptionalString(p);
}
inline NSString *JS::NativeRNLlama::NativeCompletionParams::grammar() const
{
  id const p = _v[@"grammar"];
  return RCTBridgingToOptionalString(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeCompletionParams::grammar_lazy() const
{
  id const p = _v[@"grammar_lazy"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<facebook::react::LazyVector<JS::NativeRNLlama::NativeCompletionParamsGrammar_triggersElement>> JS::NativeRNLlama::NativeCompletionParams::grammar_triggers() const
{
  id const p = _v[@"grammar_triggers"];
  return RCTBridgingToOptionalVec(p, ^JS::NativeRNLlama::NativeCompletionParamsGrammar_triggersElement(id itemValue_0) { return JS::NativeRNLlama::NativeCompletionParamsGrammar_triggersElement(itemValue_0); });
}
inline std::optional<facebook::react::LazyVector<NSString *>> JS::NativeRNLlama::NativeCompletionParams::preserved_tokens() const
{
  id const p = _v[@"preserved_tokens"];
  return RCTBridgingToOptionalVec(p, ^NSString *(id itemValue_0) { return RCTBridgingToString(itemValue_0); });
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::chat_format() const
{
  id const p = _v[@"chat_format"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<facebook::react::LazyVector<NSString *>> JS::NativeRNLlama::NativeCompletionParams::stop() const
{
  id const p = _v[@"stop"];
  return RCTBridgingToOptionalVec(p, ^NSString *(id itemValue_0) { return RCTBridgingToString(itemValue_0); });
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::n_predict() const
{
  id const p = _v[@"n_predict"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::n_probs() const
{
  id const p = _v[@"n_probs"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::top_k() const
{
  id const p = _v[@"top_k"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::top_p() const
{
  id const p = _v[@"top_p"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::min_p() const
{
  id const p = _v[@"min_p"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::xtc_probability() const
{
  id const p = _v[@"xtc_probability"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::xtc_threshold() const
{
  id const p = _v[@"xtc_threshold"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::typical_p() const
{
  id const p = _v[@"typical_p"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::temperature() const
{
  id const p = _v[@"temperature"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::penalty_last_n() const
{
  id const p = _v[@"penalty_last_n"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::penalty_repeat() const
{
  id const p = _v[@"penalty_repeat"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::penalty_freq() const
{
  id const p = _v[@"penalty_freq"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::penalty_present() const
{
  id const p = _v[@"penalty_present"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::mirostat() const
{
  id const p = _v[@"mirostat"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::mirostat_tau() const
{
  id const p = _v[@"mirostat_tau"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::mirostat_eta() const
{
  id const p = _v[@"mirostat_eta"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::dry_multiplier() const
{
  id const p = _v[@"dry_multiplier"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::dry_base() const
{
  id const p = _v[@"dry_base"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::dry_allowed_length() const
{
  id const p = _v[@"dry_allowed_length"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::dry_penalty_last_n() const
{
  id const p = _v[@"dry_penalty_last_n"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<facebook::react::LazyVector<NSString *>> JS::NativeRNLlama::NativeCompletionParams::dry_sequence_breakers() const
{
  id const p = _v[@"dry_sequence_breakers"];
  return RCTBridgingToOptionalVec(p, ^NSString *(id itemValue_0) { return RCTBridgingToString(itemValue_0); });
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::top_n_sigma() const
{
  id const p = _v[@"top_n_sigma"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeCompletionParams::ignore_eos() const
{
  id const p = _v[@"ignore_eos"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<facebook::react::LazyVector<facebook::react::LazyVector<double>>> JS::NativeRNLlama::NativeCompletionParams::logit_bias() const
{
  id const p = _v[@"logit_bias"];
  return RCTBridgingToOptionalVec(p, ^facebook::react::LazyVector<double>(id itemValue_0) { return RCTBridgingToVec(itemValue_0, ^double(id itemValue_1) { return RCTBridgingToDouble(itemValue_1); }); });
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::seed() const
{
  id const p = _v[@"seed"];
  return RCTBridgingToOptionalDouble(p);
}
inline bool JS::NativeRNLlama::NativeCompletionParams::emit_partial_completion() const
{
  id const p = _v[@"emit_partial_completion"];
  return RCTBridgingToBool(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeEmbeddingParams::embd_normalize() const
{
  id const p = _v[@"embd_normalize"];
  return RCTBridgingToOptionalDouble(p);
}
#endif // RNLlamaSpec_H
